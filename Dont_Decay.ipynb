{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Project: #\n",
    "**Reproducibility of fundings of the \"DONâ€™T DECAY THE LEARNING RATE, INCREASE THE BATCH SIZE\" conference paper by Google:** <br>\n",
    "https://openreview.net/pdf?id=B1Yy1BxCZ<br>\n",
    "*Author: Igor Tryhub, 275235*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining an image classifier convolutional neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining an image classifier ResNet model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BasickBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out, stride=1):\n",
    "        super(BasickBlock, self).__init__()\n",
    "        self.connection = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(n_in, n_out, 3, stride, 1, bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(n_out)),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('conv2', nn.Conv2d(n_out, n_out, 3, 1, 1, bias=False)),\n",
    "            ('norm2', nn.BatchNorm2d(n_out)),\n",
    "        ]))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(n_in, n_out, 1, stride, bias=False),\n",
    "            nn.BatchNorm2d(n_out),\n",
    "        )\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        mapping = self.connection(x)\n",
    "        if self.stride != 1:\n",
    "            x = self.downsample(x)\n",
    "        return self.relu(mapping + x)\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out, n_block, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.blocks = nn.Sequential()\n",
    "        self.blocks.add_module('block0', BasickBlock(n_in, n_out, stride))\n",
    "        for i in range(n_block - 1):\n",
    "            self.blocks.add_module('block{}'.format(i + 1), BasickBlock(n_out, n_out))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)\n",
    "\n",
    "\n",
    "class ResNetCifar10(nn.Module):\n",
    "\n",
    "    def __init__(self, n_block=3):\n",
    "        super(ResNetCifar10, self).__init__()\n",
    "        ch = [4, 8, 16]#ch = [16, 32, 64]\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(3, ch[0], 3, 1, 1, bias=False)),\n",
    "            ('norm1', nn.BatchNorm2d(ch[0])),\n",
    "            ('relu1', nn.ReLU(inplace=True)),\n",
    "            ('resb1', ResidualBlock(ch[0], ch[0], n_block)),\n",
    "            ('resb2', ResidualBlock(ch[0], ch[1], n_block, 2)),\n",
    "            ('resb3', ResidualBlock(ch[1], ch[2], n_block, 2)),\n",
    "            ('avgpl', nn.AvgPool2d(8)),\n",
    "        ]))\n",
    "        self.fc = nn.Linear(ch[2], 10)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global meta-settings and initial values of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = ResNetCifar10()\n",
    "N = 50000\n",
    "batch_size = 256\n",
    "weight_decay=0.0005\n",
    "momentum=0.9\n",
    "lr=0.1\n",
    "batch_scaling_coef = batch_size/lr #for future use\n",
    "stat_every = 5000\n",
    "epoch = 0\n",
    "max_epochs = 180\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr, momentum, weight_decay)\n",
    "history = {'train_losses': [], 'test_accuracies': []}\n",
    "scenarios = {'learn_decay': 0, 'hybrid': 1, 'batch_increase': 2}\n",
    "original_update_every = 60\n",
    "update_every = 10\n",
    "original_factor = 5\n",
    "update_asif_original_factor = 4\n",
    "update_factor = 1/(1.0/update_asif_original_factor)**(1.0/(original_update_every/update_every))\n",
    "model_state_path = 'checkpoint.pth.tar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way to save state of parameters in case kernel dies during computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=model_state_path):\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting function for the batch train loss and batch test accuracy plotting with respect to the batch number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    figsize(16, 4)\n",
    "    \n",
    "    subplot(1,2,1)\n",
    "    train_loss = np.array(history['train_losses'])\n",
    "    semilogy(np.arange(train_loss.shape[0]), train_loss, label='Training cross-entropy')\n",
    "    legend()\n",
    "        \n",
    "    subplot(1,2,2)\n",
    "    test_accuracies = np.array(history['test_accuracies'])\n",
    "    plot(np.arange(test_accuracies.shape[0]), test_accuracies, label='Test set accuracy',color='g')\n",
    "    legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input CIFAR-10 dataset data transforming and splitting for a training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining parameter update at 3 different convergence scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_update(epoch, scenario, optimizer, trainloader):\n",
    "    if scenario == scenarios['learn_decay']:\n",
    "        if epoch and not (epoch % update_every):\n",
    "            optimizer.param_groups[0]['lr'] /= update_factor\n",
    "            \n",
    "    elif scenario == scenarios['hybrid']:\n",
    "        if epoch and not (epoch % 50):\n",
    "            trainloader.batch_size *= 4\n",
    "            trainloader = torch.utils.data.DataLoader(trainset, batch_size=trainloader.batch_size,\n",
    "                                                shuffle=True, num_workers=1)\n",
    "            if epoch >= 100:\n",
    "                optimizer.param_groups[0]['lr'] /= 4\n",
    "        \n",
    "    elif scenario == scenarios['batch_increase']:\n",
    "        if epoch and not (epoch % update_every):\n",
    "            trainloader.batch_size = int(trainloader.batch_size * update_factor)\n",
    "            trainloader = torch.utils.data.DataLoader(trainset, batch_size=trainloader.batch_size,\n",
    "                                                shuffle=True, num_workers=1)\n",
    "            \n",
    "    return optimizer, trainloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Training the neural network using Stochastic Gradient Descent (SGD) and measuring loss as cross-entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(epoch, scenario, optimizer, trainloader):\n",
    "    net.train()\n",
    "        \n",
    "    optimizer, trainloader = param_update(epoch, scenario, optimizer, trainloader)\n",
    "    print(\"Epoch: {}      batch size: {}      learning rate: {}      weight decay: {}\")\\\n",
    "        .format(epoch+1, trainloader.batch_size, optimizer.param_groups[0]['lr'], weight_decay)\n",
    "\n",
    "    total = 0\n",
    "    errors = 0\n",
    "    train_loss = 0\n",
    "    processed = 0\n",
    "    for data in trainloader:\n",
    "        processed += int(data[1].size()[0])\n",
    "        inputs, labels = data # get the inputs            \n",
    "        inputs, labels = Variable(inputs), Variable(labels) # wrap them in Variable\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        outputs = net.forward(inputs) # forward + backward + optimize\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        errors += (predicted != labels.data).sum()\n",
    "        train_loss += loss.data[0]\n",
    "        if (processed // stat_every):    # print loss statistics every `stat_every` processed elements\n",
    "            print('\\tLoss: %.3f' % (loss.data[0]))\n",
    "            processed -= stat_every\n",
    "            \n",
    "    correct = total-errors\n",
    "    train_accuracy = 100.0 * correct / total\n",
    "    history['train_losses'].append(train_loss)\n",
    "    print('\\tAccuracy for training epoch: %.2f%%' % (train_accuracy))\n",
    "    \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'state_dict': net.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'scenario' : scenario,\n",
    "        'trainloader' : trainloader,\n",
    "        'history' : history,\n",
    "    })\n",
    "    print(\"\\tCheckpoint saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Testing the network on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(epoch, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    test_loss = 0\n",
    "    \n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = Variable(images), Variable(labels)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        test_loss += loss.data[0]\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "        if not((epoch+1)%5):\n",
    "            c = (predicted == labels.data).squeeze()\n",
    "            for i in range(int(data[1].size()[0])):\n",
    "                label = labels[i]\n",
    "                class_correct[label.data[0]] += c[i]\n",
    "                class_total[label.data[0]] += 1\n",
    "    \n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    history['test_accuracies'].append(test_accuracy)\n",
    "    print('\\tAccuracy of the network on the 10000 test images: %.2f%%' % (test_accuracy))\n",
    "    if not((epoch+1)%5):\n",
    "        for i in range(10):\n",
    "            print('\\t\\tFor %5s : %2d %%' % (\n",
    "                classes[i], 100.0 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scenario = scenarios['learn_decay']\n",
    "epochs_num = max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 2.113\n",
      "\tLoss: 1.886\n",
      "\tLoss: 1.818\n",
      "\tLoss: 1.828\n",
      "\tLoss: 1.733\n",
      "\tLoss: 1.726\n",
      "\tLoss: 1.784\n",
      "\tLoss: 1.610\n",
      "\tLoss: 1.533\n",
      "\tLoss: 1.610\n",
      "\tAccuracy for training epoch: 32.36%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 42.00%\n",
      "Epoch: 2      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 1.551\n",
      "\tLoss: 1.522\n",
      "\tLoss: 1.522\n",
      "\tLoss: 1.550\n",
      "\tLoss: 1.410\n",
      "\tLoss: 1.394\n",
      "\tLoss: 1.308\n",
      "\tLoss: 1.449\n",
      "\tLoss: 1.397\n",
      "\tLoss: 1.368\n",
      "\tAccuracy for training epoch: 46.65%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 50.00%\n",
      "Epoch: 3      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 1.377\n",
      "\tLoss: 1.375\n",
      "\tLoss: 1.286\n",
      "\tLoss: 1.371\n",
      "\tLoss: 1.254\n",
      "\tLoss: 1.322\n",
      "\tLoss: 1.280\n",
      "\tLoss: 1.258\n",
      "\tLoss: 1.267\n",
      "\tLoss: 1.304\n",
      "\tAccuracy for training epoch: 53.46%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 46.00%\n",
      "Epoch: 4      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 1.142\n",
      "\tLoss: 1.191\n",
      "\tLoss: 1.249\n",
      "\tLoss: 1.122\n",
      "\tLoss: 1.189\n",
      "\tLoss: 1.263\n",
      "\tLoss: 1.147\n",
      "\tLoss: 1.176\n",
      "\tLoss: 1.233\n",
      "\tLoss: 1.100\n",
      "\tAccuracy for training epoch: 57.95%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 54.00%\n",
      "Epoch: 5      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 1.144\n",
      "\tLoss: 1.135\n",
      "\tLoss: 1.101\n",
      "\tLoss: 1.042\n",
      "\tLoss: 1.082\n",
      "\tLoss: 1.075\n",
      "\tLoss: 1.172\n",
      "\tLoss: 1.094\n",
      "\tLoss: 1.047\n",
      "\tLoss: 1.152\n",
      "\tAccuracy for training epoch: 60.16%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 60.00%\n",
      "\t\tFor plane : 70 %\n",
      "\t\tFor   car : 76 %\n",
      "\t\tFor  bird : 46 %\n",
      "\t\tFor   cat : 46 %\n",
      "\t\tFor  deer : 44 %\n",
      "\t\tFor   dog : 51 %\n",
      "\t\tFor  frog : 67 %\n",
      "\t\tFor horse : 59 %\n",
      "\t\tFor  ship : 69 %\n",
      "\t\tFor truck : 71 %\n",
      "Epoch: 6      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 1.046\n",
      "\tLoss: 1.053\n",
      "\tLoss: 1.168\n",
      "\tLoss: 1.136\n",
      "\tLoss: 1.052\n",
      "\tLoss: 1.052\n",
      "\tLoss: 1.007\n",
      "\tLoss: 1.095\n",
      "\tLoss: 1.112\n",
      "\tLoss: 1.064\n",
      "\tAccuracy for training epoch: 62.65%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 60.00%\n",
      "Epoch: 7      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 1.066\n",
      "\tLoss: 0.967\n",
      "\tLoss: 1.054\n",
      "\tLoss: 0.959\n",
      "\tLoss: 0.953\n",
      "\tLoss: 1.062\n",
      "\tLoss: 0.960\n",
      "\tLoss: 1.017\n",
      "\tLoss: 0.992\n",
      "\tLoss: 0.855\n",
      "\tAccuracy for training epoch: 63.50%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 63.00%\n",
      "Epoch: 8      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 0.994\n",
      "\tLoss: 0.999\n",
      "\tLoss: 1.057\n",
      "\tLoss: 1.029\n",
      "\tLoss: 0.920\n",
      "\tLoss: 1.081\n",
      "\tLoss: 0.977\n",
      "\tLoss: 1.073\n",
      "\tLoss: 0.930\n",
      "\tLoss: 1.086\n",
      "\tAccuracy for training epoch: 64.98%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 63.00%\n",
      "Epoch: 9      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 0.905\n",
      "\tLoss: 0.846\n",
      "\tLoss: 0.985\n",
      "\tLoss: 0.950\n",
      "\tLoss: 1.089\n",
      "\tLoss: 0.880\n",
      "\tLoss: 0.951\n",
      "\tLoss: 0.889\n",
      "\tLoss: 0.857\n",
      "\tLoss: 1.010\n",
      "\tAccuracy for training epoch: 65.77%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 63.00%\n",
      "Epoch: 10      batch size: 256      learning rate: 0.1      weight decay: 0.0005\n",
      "\tLoss: 0.910\n",
      "\tLoss: 0.965\n",
      "\tLoss: 0.921\n",
      "\tLoss: 1.120\n",
      "\tLoss: 0.943\n",
      "\tLoss: 0.819\n",
      "\tLoss: 0.924\n",
      "\tLoss: 0.956\n",
      "\tLoss: 0.864\n",
      "\tLoss: 0.984\n",
      "\tAccuracy for training epoch: 67.20%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 64.00%\n",
      "\t\tFor plane : 69 %\n",
      "\t\tFor   car : 78 %\n",
      "\t\tFor  bird : 49 %\n",
      "\t\tFor   cat : 46 %\n",
      "\t\tFor  deer : 55 %\n",
      "\t\tFor   dog : 55 %\n",
      "\t\tFor  frog : 75 %\n",
      "\t\tFor horse : 65 %\n",
      "\t\tFor  ship : 64 %\n",
      "\t\tFor truck : 82 %\n",
      "Epoch: 11      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.968\n",
      "\tLoss: 0.951\n",
      "\tLoss: 0.901\n",
      "\tLoss: 0.828\n",
      "\tLoss: 0.954\n",
      "\tLoss: 0.905\n",
      "\tLoss: 0.948\n",
      "\tLoss: 0.874\n",
      "\tLoss: 0.949\n",
      "\tLoss: 1.166\n",
      "\tAccuracy for training epoch: 68.64%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 65.00%\n",
      "Epoch: 12      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.825\n",
      "\tLoss: 0.874\n",
      "\tLoss: 0.826\n",
      "\tLoss: 0.825\n",
      "\tLoss: 0.960\n",
      "\tLoss: 0.865\n",
      "\tLoss: 0.880\n",
      "\tLoss: 1.018\n",
      "\tLoss: 0.849\n",
      "\tLoss: 0.825\n",
      "\tAccuracy for training epoch: 69.38%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 68.00%\n",
      "Epoch: 13      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.822\n",
      "\tLoss: 0.785\n",
      "\tLoss: 0.728\n",
      "\tLoss: 0.805\n",
      "\tLoss: 0.970\n",
      "\tLoss: 0.842\n",
      "\tLoss: 0.880\n",
      "\tLoss: 0.808\n",
      "\tLoss: 0.911\n",
      "\tLoss: 0.856\n",
      "\tAccuracy for training epoch: 69.84%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 68.00%\n",
      "Epoch: 14      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.877\n",
      "\tLoss: 0.824\n",
      "\tLoss: 0.967\n",
      "\tLoss: 0.873\n",
      "\tLoss: 0.800\n",
      "\tLoss: 0.921\n",
      "\tLoss: 0.775\n",
      "\tLoss: 0.935\n",
      "\tLoss: 0.830\n",
      "\tLoss: 0.757\n",
      "\tAccuracy for training epoch: 70.26%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 69.00%\n",
      "Epoch: 15      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.753\n",
      "\tLoss: 0.884\n",
      "\tLoss: 0.796\n",
      "\tLoss: 0.825\n",
      "\tLoss: 0.818\n",
      "\tLoss: 0.737\n",
      "\tLoss: 0.818\n",
      "\tLoss: 0.908\n",
      "\tLoss: 0.905\n",
      "\tLoss: 0.866\n",
      "\tAccuracy for training epoch: 70.98%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 70.00%\n",
      "\t\tFor plane : 77 %\n",
      "\t\tFor   car : 87 %\n",
      "\t\tFor  bird : 57 %\n",
      "\t\tFor   cat : 51 %\n",
      "\t\tFor  deer : 64 %\n",
      "\t\tFor   dog : 66 %\n",
      "\t\tFor  frog : 69 %\n",
      "\t\tFor horse : 73 %\n",
      "\t\tFor  ship : 80 %\n",
      "\t\tFor truck : 74 %\n",
      "Epoch: 16      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.793\n",
      "\tLoss: 0.723\n",
      "\tLoss: 0.802\n",
      "\tLoss: 0.758\n",
      "\tLoss: 0.829\n",
      "\tLoss: 0.829\n",
      "\tLoss: 0.717\n",
      "\tLoss: 0.740\n",
      "\tLoss: 0.801\n",
      "\tLoss: 0.983\n",
      "\tAccuracy for training epoch: 71.36%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 68.00%\n",
      "Epoch: 17      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.876\n",
      "\tLoss: 0.744\n",
      "\tLoss: 0.786\n",
      "\tLoss: 0.737\n",
      "\tLoss: 0.771\n",
      "\tLoss: 0.828\n",
      "\tLoss: 0.759\n",
      "\tLoss: 0.729\n",
      "\tLoss: 0.879\n",
      "\tLoss: 1.177\n",
      "\tAccuracy for training epoch: 71.88%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 70.00%\n",
      "Epoch: 18      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.834\n",
      "\tLoss: 0.886\n",
      "\tLoss: 0.816\n",
      "\tLoss: 0.939\n",
      "\tLoss: 0.906\n",
      "\tLoss: 0.732\n",
      "\tLoss: 0.748\n",
      "\tLoss: 0.630\n",
      "\tLoss: 0.805\n",
      "\tLoss: 0.855\n",
      "\tAccuracy for training epoch: 72.15%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 68.00%\n",
      "Epoch: 19      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.755\n",
      "\tLoss: 0.792\n",
      "\tLoss: 0.760\n",
      "\tLoss: 0.731\n",
      "\tLoss: 0.986\n",
      "\tLoss: 0.852\n",
      "\tLoss: 0.795\n",
      "\tLoss: 0.712\n",
      "\tLoss: 0.737\n",
      "\tLoss: 0.811\n",
      "\tAccuracy for training epoch: 72.38%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 71.00%\n",
      "Epoch: 20      batch size: 256      learning rate: 0.0793700525984      weight decay: 0.0005\n",
      "\tLoss: 0.810\n",
      "\tLoss: 0.787\n",
      "\tLoss: 0.888\n",
      "\tLoss: 0.886\n",
      "\tLoss: 0.704\n",
      "\tLoss: 0.683\n",
      "\tLoss: 0.747\n",
      "\tLoss: 0.798\n",
      "\tLoss: 0.767\n",
      "\tLoss: 0.636\n",
      "\tAccuracy for training epoch: 72.98%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 70.00%\n",
      "\t\tFor plane : 78 %\n",
      "\t\tFor   car : 86 %\n",
      "\t\tFor  bird : 53 %\n",
      "\t\tFor   cat : 52 %\n",
      "\t\tFor  deer : 67 %\n",
      "\t\tFor   dog : 51 %\n",
      "\t\tFor  frog : 68 %\n",
      "\t\tFor horse : 75 %\n",
      "\t\tFor  ship : 84 %\n",
      "\t\tFor truck : 86 %\n",
      "Epoch: 21      batch size: 256      learning rate: 0.0629960524947      weight decay: 0.0005\n",
      "\tLoss: 0.788\n",
      "\tLoss: 0.683\n",
      "\tLoss: 0.748\n",
      "\tLoss: 0.692\n",
      "\tLoss: 0.626\n",
      "\tLoss: 0.739\n",
      "\tLoss: 0.716\n",
      "\tLoss: 0.692\n",
      "\tLoss: 0.693\n",
      "\tLoss: 0.798\n",
      "\tAccuracy for training epoch: 73.65%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 72.00%\n",
      "Epoch: 22      batch size: 256      learning rate: 0.0629960524947      weight decay: 0.0005\n",
      "\tLoss: 0.840\n",
      "\tLoss: 0.765\n",
      "\tLoss: 0.841\n",
      "\tLoss: 0.800\n",
      "\tLoss: 0.716\n",
      "\tLoss: 0.628\n",
      "\tLoss: 0.710\n",
      "\tLoss: 0.742\n",
      "\tLoss: 0.898\n",
      "\tLoss: 0.818\n",
      "\tAccuracy for training epoch: 74.02%\n",
      "\tCheckpoint saved!\n",
      "\tAccuracy of the network on the 10000 test images: 72.00%\n",
      "Epoch: 23      batch size: 256      learning rate: 0.0629960524947      weight decay: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-45:\n",
      "  File \"/home/igort/anaconda3/envs/my_env/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "    self.run()\n",
      "  File \"/home/igort/anaconda3/envs/my_env/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/igort/anaconda3/envs/my_env/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/igort/anaconda3/envs/my_env/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "    return recv()\n",
      "  File \"/home/igort/anaconda3/envs/my_env/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-23455ece0f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mepoch\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-6b6b196b2096>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, scenario, optimizer, trainloader)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igort/anaconda3/envs/my_env/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/igort/anaconda3/envs/my_env/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(max_epochs-epoch):\n",
    "    if epoch==epochs_num:\n",
    "        break\n",
    "    train(epoch, scenario, optimizer, trainloader)\n",
    "    test(epoch, testloader)\n",
    "    epoch+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAD8CAYAAACy2mOCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAEBg/D+PlhkcCrFeAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a60d635d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=========================================================================================================================\n",
    "## CAUTION: the following cell loads last serialized parameters from memory and overwrites the current state: ##\n",
    "========================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(model_state_path):\n",
    "    checkpoint = torch.load(model_state_path)\n",
    "    epoch = checkpoint['epoch'] + 1\n",
    "    net.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scenario = checkpoint['scenario']\n",
    "    trainloader = checkpoint['trainloader']\n",
    "    history = checkpoint['history']\n",
    "    print(\"Checkpoint successfully loaded from '{}'!\".format(model_state_path))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:my_env]",
   "language": "python",
   "name": "conda-env-my_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
